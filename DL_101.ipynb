{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_101",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/uanl-workshop/blob/master/DL_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Introducción a las Deep Learning con Rodo\n",
        "\n",
        "## Contenidos\n",
        "\n",
        "### Sección I\n",
        "\n",
        "1. Brief histórico\n",
        "2. Un perceptrón\n",
        "3. Activación y bias\n",
        "\n",
        "### Sección II\n",
        "\n",
        "4. Aprendizaje de neuronas\n",
        "5. Entrenamiento de una neurona\n",
        "6. Predicciones\n",
        "\n",
        "### Sección III\n",
        "\n",
        "7. El dataset a utilizar\n",
        "8. Preparación de los datos\n",
        "9. Creación de una red neuronal\n",
        "10. Entrenamiento del modelo\n",
        "11. Evaluación y predicción\n",
        "\n",
        "### ¡Reto!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Sección I**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk1Rkc4FZ5g"
      },
      "source": [
        "### **Historia de las redes neuronales**\n",
        "\n",
        "La historia de las redes neuronales se remontan a un tipo de neurona artificial, llamada **perceptrón**. Estos fueron desarrollados entre 1950 y 1960 por el científico **Frank Rosenblatt**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uehq48zoSocy"
      },
      "source": [
        "\n",
        "\n",
        "### **Entonces, ¿qué es un perceptrón?**\n",
        "\n",
        "Un perceptrón es una abstracción de una neurona real.\n",
        "\n",
        "Éste toma varias **entradas** $x_1, x_2,..., x_n $ y produce una **salida**. Para la salida, Rosenblatt propuso que las entradas tuviesen **pesos** asciados $w_1, w_2, ..., w_n$, siendo estos números reales que expresan la importancia respectiva de cada entrada para la salida. La salida de la neurona, $0$ o $1$, está determinada con base en que la suma ponderada, \n",
        "\n",
        "$$\\displaystyle\\sum_{j}w_jx_j,$$\n",
        "\n",
        "<!-- $\\textbf{w}_{Layer}\\cdot\\textbf{x} = \n",
        "\\begin{bmatrix}\n",
        "w_{1, 1} & w_{1, 2} & \\cdots & w_{1, n}\\\\\n",
        "w_{2, 1} & w_{2, 2} & \\cdots & w_{2, n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "w_{m, 1} & w_{m, 2} & \\cdots & w_{m, n}\\\\\n",
        "\\end{bmatrix} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "\\vdots\\\\\n",
        "x_n\n",
        "\\end{bmatrix}$ -->\n",
        "\n",
        "(para $j \\in \\{1, 2, ..., n\\}$ ) sea menor o mayor que un **valor límite** que por ahora llamaremos umbral.\n",
        "\n",
        "Resumiendo, un perceptron es un sistema que toma decisiones con base en la evidencia presentada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33kCpXyFgJ_"
      },
      "source": [
        "#### **Implementemos un perceptrón**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLBMuek3lBHd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Primero creamos nuestra clase perceptron\n",
        "class Perceptron():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "  \n",
        "    def decide(self, treshold):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        treshold : int\n",
        "            Threshold value for decision.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42O74IdmKIw"
      },
      "source": [
        "# Now, we need to set inputs and weights\n",
        "inputs, weights = [], []\n",
        "\n",
        "questions = [\n",
        "    \"· ¿Cuál es la velocidad? \",\n",
        "    \"· ¿Ritmo cardiaco? \",\n",
        "    \"· ¿Respiración? \"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    i = int(input(question))\n",
        "    w = int(input(\"· Y su peso asociado es... \"))\n",
        "    inputs.append(i)\n",
        "    weights.append(w)\n",
        "    print()\n",
        "\n",
        "treshold = int(input(\"· Y nuestro umbral/límite será: \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHjy-k33oNFm"
      },
      "source": [
        "p = Perceptron() # TODO Instantiate Perceptron\n",
        "p.decide(treshold) # TODO Apply decision function with threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCCwUG6DgCX"
      },
      "source": [
        "### **Bias y funciones de activación**\n",
        "\n",
        "_Antes de seguir, introduciremos otro concepto, que es el **bias**._\n",
        "\n",
        "La operación matemática que realiza la neurona se puede escribir como:\n",
        "\n",
        "$$ f(\\textbf{x}) = \n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j <$ valor límite o treshold} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j \\geq$ valor límite o treshold} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $\\textbf{x} = (x_1, x_2, ..., x_n)$ y $j \\in \\{1, 2, ..., n\\}$.\n",
        "\n",
        "De lo anterior, podemos despejar el valor límite (el umbral) y escribirlo como $b$, obteniendo:\n",
        "\n",
        "$$ f(\\textbf{x}) = \n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b < 0$} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b > 0$} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $\\textbf{x} = (x_1, x_2, ..., x_n)$ y $j \\in \\{1, 2, ..., n\\}$.\n",
        "\n",
        "Esto que escribimos como $b$, también se le conoce como **bias**, y describe *qué tan susceptible la red es a __dispararse__*.\n",
        "\n",
        "Curiosamente, esta descripción matemática encaja con la función de salto, que es una función de activación. Esto es, una función que permite el paso de información de acuerdo a la entrada y los pesos, permitiendo el disparo del lo procesado hacia la salida. La función de salto se ve como sigue:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4a/Funci%C3%B3n_Cu_H.svg\" width=\"40%\" alt=\"Función escalón de Heaviside\">\n",
        "</center>\n",
        "\n",
        "Sin embargo, podemos hacer a una neurona aún más susceptible con respecto a los datos de la misma (entradas, pesos, bias) añadiendo una función sigmoide. La función sigmoide se ve como a continuación: \n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Funci%C3%B3n_sigmoide_01.svg\" width=\"40%\" alt=\"Función sigmoide\">\n",
        "</center>\n",
        "\n",
        "Esta función es suave, y por lo tanto tiene una diferente \"sensibililad\" a los cambios abruptos de valores. También, sus entradas en lugar de solo ser $1$'s o $0$'s, pueden ser valores en todos los números reales. La función sigmoide es descrita por la siguiente expresión matemática:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+e^{-z}}$$\n",
        "\n",
        "O escrito en términos de pesos y biases:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+\\exp{\\left\\{-\\left(\\displaystyle\\sum_{j}w_jx_j +b\\right)\\right\\}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G1MY4HQFsEd"
      },
      "source": [
        "#### **Volviendo al ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSn8VaEoDtHo"
      },
      "source": [
        "# Modificamos para añadir la función de activación\n",
        "class Neuron():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "  \n",
        "    def decide(self, bias):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bias : int\n",
        "            The bias value for operation.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data + bias\n",
        "        # TODO: Apply sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPy6NpfERfJ"
      },
      "source": [
        "bias = int(input(\"· El nuevo bias será: \"))\n",
        "s = Neuron(inputs, weights)\n",
        "s.decide(bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRGlbVZsFxdk"
      },
      "source": [
        "> Esta es la neurona que usaremos para los siguientes tópicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvmIk2G9EgOQ"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnY-np7LE3lS"
      },
      "source": [
        "## **Sección II**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aprendizaje de neuronas\n",
        "\n",
        "Veamos cómo se puede entrenar una sola neurona para hacer una predicción.\n",
        "\n",
        "Para este problema construiremos un perceptrón simple, como el propuesto por McCulloch & Pitts, usando la función sigmoide.\n",
        "\n",
        "#### **Planteamiento del problema:**\n",
        "\n",
        "Queremos mostrarle a una neurona simple un conjunto de ejemplos para que pueda aprender cómo se comporta una función. El conjunto de ejemplos es el siguiente:\n",
        "\n",
        "- `(1, 0)` debería devolver `1`.\n",
        "- `(0, 1)` debe devolver `1`.\n",
        "- `(0, 0)` debería devolver `0`.\n",
        "\n",
        "Entonces, si ingresamos a la neurona el valor de `(1, 1)`, debería poder predecir el número `1`.\n",
        "\n",
        "> ¿Puedes adivinar la función?\n",
        "\n",
        "#### ¿Que necesitamos hacer?\n",
        "\n",
        "Programar y entrenar una neurona para hacer predicciones.\n",
        "\n",
        "En concreto, vamos a hacer lo siguiente:\n",
        "\n",
        "- Construir la clase y su constructor.\n",
        "- Definir la función sigmoide y su derivada\n",
        "- Definir el número de épocas para el entrenamiento.\n",
        "- Resolver el problema y predecir el valor de la entrada deseada"
      ],
      "metadata": {
        "id": "I7-Ja9DK9cIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class smart_neuron():\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        n : int\n",
        "            Input size.\n",
        "        \"\"\"\n",
        "        \n",
        "        np.random.seed(123)\n",
        "        self.synaptic_weights = None # TODO. Use np.random.random((n, 1)) to gen values in (-1, 1)\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        \"\"\"Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to sigmoid function.\n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO: Return result of sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        return None\n",
        "\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to evaluated sigmoid function.\"\"\"\n",
        "\n",
        "        # TODO: Return the derivate of sigmoid function x * (1 - x)\n",
        "        return None\n",
        "\n",
        "    def train(self, training_inputs, training_output, iterations):\n",
        "        \"\"\"Training function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        training_inputs : list\n",
        "            List of features for training.\n",
        "        training_outputs : list\n",
        "            List of labels for training.\n",
        "        iterations : int\n",
        "            Number of iterations for training.\n",
        "        \"\"\"\n",
        "        \n",
        "        for iteration in range(iterations):\n",
        "            output = self.predict(training_inputs)\n",
        "            error = training_output.reshape((len(training_inputs), 1)) - output\n",
        "            adjustment = np.dot(training_inputs.T, error *\n",
        "                                self.__sigmoid_derivative(output))\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Prediction function. Applies input function to inputs tensor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of inputs to apply sigmoid function.\n",
        "        \"\"\"\n",
        "        # TODO: Apply self.__sigmoid to np.dot of (inputs, self.synaptic_weights)\n",
        "        return None"
      ],
      "metadata": {
        "id": "2NKx40hxqmo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generando las muestras\n",
        "\n",
        "Ahora podemos generar una lista de ejemplos basados en la descripción del problema."
      ],
      "metadata": {
        "id": "Ym_oEzbhxYKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training samples:\n",
        "input_values = []   # TODO. Define the input values as a list of tuples\n",
        "output_values = []  # TODO. Define the desired outputs\n",
        "\n",
        "training_inputs = np.array(input_values)\n",
        "training_output = np.array(output_values).T.reshape((3, 1))"
      ],
      "metadata": {
        "id": "BYW9aYSCxc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando la neurona\n",
        "\n",
        "Para hacer el entrenamiento, primero definiremos una neurona. De forma predeterminada, contendrá pesos aleatorios (ya que aún no se ha entrenado):"
      ],
      "metadata": {
        "id": "DJUYV8H-xf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Sigmoid Neuron:\n",
        "neuron = smart_neuron(2)\n",
        "print(\"Initial random weights:\")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "cThkcQGMxrX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO.\n",
        "# We can modify the number of epochs to see how it performs.\n",
        "epochs = 0\n",
        "\n",
        "# We train the neuron a number of epochs:\n",
        "neuron.train(training_inputs, training_output, epochs)\n",
        "print(\"New synaptic weights after training: \")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "WnuCP6eHxtQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Realizando predicciones"
      ],
      "metadata": {
        "id": "7vPb5a65x0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We predict to verify the performance:\n",
        "one_one = np.array((1, 1))\n",
        "print(\"Prediction for (1, 1): \")\n",
        "neuron.predict(one_one)"
      ],
      "metadata": {
        "id": "5FAcuADc9bST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IHtR4uPEaCO"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NE4e3KuEVst"
      },
      "source": [
        "## **Sección III**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z7JrTygMDSx"
      },
      "source": [
        "### El dataset a utilizar: Coca-Pepsi\n",
        "\n",
        "Comencemos importando TensorFlow. Para posteriormente cargar los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPB4nBh8MFDm"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar los datos, clonaremos algunos que tengo preparados para ustedes en GitHub."
      ],
      "metadata": {
        "id": "UVg0AU2-Fqzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RodolfoFerro/uanl-workshop.git"
      ],
      "metadata": {
        "id": "1S81FXVEFzQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos la cantidad de imágenes que tenemos por folder."
      ],
      "metadata": {
        "id": "E2tUmwcxGskw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "size = 128\n",
        "\n",
        "\n",
        "data_dir_train = 'uanl-workshop/data/pepsi-coke/train'\n",
        "data_dir_test = 'uanl-workshop/data/pepsi-coke/test'\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    image_size=(size, size),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir_test,\n",
        "    seed=123,\n",
        "    image_size=(size, size),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "DmZ_sDYTH7lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploremos las imágenes."
      ],
      "metadata": {
        "id": "FgHZNETaJ2aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "IFQsFoLWJ-VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "6FfeT7jUJ0n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxfNdPU3NQge"
      },
      "source": [
        "### Preparación de los datos\n",
        "\n",
        "Todos los valores de las imágenes están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si transformamos los valores para tratar todos con valores entre 0 y 1. Este proceso se llama **estandarización** y se puede hacer usando `tf.keras.layers.Rescaling` al momento de crear el modelo.\n",
        "\n",
        "Lo que pocede ahora es trabajar en la preparación de los datos (cache) para posteriormente desarrollar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "4fh3DURvLBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación de una red neuronal\n",
        "\n",
        "A continuación aprenderemos a utilizar TensorFlow para crear una red neuronal."
      ],
      "metadata": {
        "id": "npjrVs7jUBC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "NWIxFHNsLQIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "2eylVlHxLR6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Para entrenar el modelo, simplemente utilizamos el método `.fit()` del modelo."
      ],
      "metadata": {
        "id": "B4DmYPVAUJ2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "X6WpyTNdLVU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim((0,1.01))\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.grid('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eHmZ4nnccToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación y predicción"
      ],
      "metadata": {
        "id": "_2oyTh_jMAIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "buRgAf7xLvln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "test_path = 'uanl-workshop/data/pepsi-coke/test'\n",
        "test_path_coke = os.path.join(test_path, 'cocacola')\n",
        "test_path_pepsi = os.path.join(test_path, 'pepsi')\n",
        "\n",
        "\n",
        "sample_index = 20\n",
        "in_img = cv2.imread(os.path.join(test_path_coke, f'{sample_index}.jpg'))\n",
        "in_img = cv2.cvtColor(in_img, cv2.COLOR_BGR2RGB)\n",
        "in_img = cv2.resize(in_img, (size, size))\n",
        "\n",
        "plt.imshow(in_img)\n",
        "plt.axis('off')\n",
        "print('Prediction:', model.predict(np.expand_dims(in_img, axis=0)))"
      ],
      "metadata": {
        "id": "kLqvq2cnUfdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ],
      "metadata": {
        "id": "hMCddqlrYosR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **¡Reto!**\n",
        "\n",
        "Ahora vamos a crear un clasificador de imágenes utilizando un conjunto de datos sobre perritos y gatitos.\n",
        "\n",
        "**¡El reto consiste en obtener el accuracy más alto del grupo!**"
      ],
      "metadata": {
        "id": "66EmBlBDYsh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "\n",
        "HEIGHT = 128\n",
        "WIDTH = 128\n",
        "class_names = ['cat', 'dog']\n",
        "split = ['train[:70%]', 'train[70%:]']\n",
        "\n",
        "def preprocess(img, label):\n",
        "    return tf.image.resize(img, [HEIGHT, WIDTH]) / 255, label\n",
        "\n",
        "\n",
        "# Load and prepare data\n",
        "train_ds, test_ds = tfds.load(name='cats_vs_dogs', split=split, as_supervised=True)\n",
        "train_ds = train_ds.map(preprocess).batch(32)\n",
        "test_ds = test_ds.map(preprocess).batch(32)\n",
        "\n",
        "\n",
        "# Build model\n",
        "mlp_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Train model\n",
        "history = mlp_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "\n",
        "# Plot training\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim((0,1.01))\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.grid('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xb7t65eKYx_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "UpVZ1aLuZbGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2022. <br>\n",
        "> Puedes contactarme a través de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o Twitter ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ],
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      }
    }
  ]
}